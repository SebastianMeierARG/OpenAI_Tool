{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding and loading pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\semeier\\Desktop\\gemini_chat-main\\gemini_chat-main\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import fitz  # PyMuPDF for PDF extraction\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import faiss  # Vector search\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# =========================\n",
    "# Setup\n",
    "# =========================\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "SERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 8 PDFs from ./pdf_files/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding PDF chunks ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 18/18 [00:16<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF index built with 545 chunks. Embedding dim=384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY not found in .env\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "# Embeddings model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# =========================\n",
    "# PDF ingestion + chunking\n",
    "# =========================\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = []\n",
    "    for page in doc:\n",
    "        text.append(page.get_text())\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.replace(\"\\u00a0\", \" \")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 1100, overlap: int = 150) -> List[str]:\n",
    "    chunks, i = [], 0\n",
    "    while i < len(text):\n",
    "        chunks.append(text[i:i+chunk_size])\n",
    "        i += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "pdf_folder = \"./pdf_files/\"\n",
    "if not os.path.isdir(pdf_folder):\n",
    "    raise FileNotFoundError(f\"Folder '{pdf_folder}' not found. Create it and add PDFs.\")\n",
    "\n",
    "documents, doc_sources = [], []\n",
    "pdf_chunks, pdf_chunk_meta = [], []\n",
    "\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.lower().endswith(\".pdf\")]\n",
    "if not pdf_files:\n",
    "    raise RuntimeError(\"No PDFs found in ./pdf_files/. Please add at least one PDF.\")\n",
    "\n",
    "print(f\"Loading {len(pdf_files)} PDFs from {pdf_folder} ...\")\n",
    "for file in tqdm(pdf_files):\n",
    "    file_path = os.path.join(pdf_folder, file)\n",
    "    raw = extract_text_from_pdf(file_path)\n",
    "    raw = clean_text(raw)\n",
    "    documents.append(raw)\n",
    "    doc_sources.append(file)\n",
    "\n",
    "    chunks = chunk_text(raw, chunk_size=1100, overlap=150)\n",
    "    for ci, c in enumerate(chunks):\n",
    "        pdf_chunks.append(c)\n",
    "        pdf_chunk_meta.append({\"source\": file, \"chunk_id\": ci})\n",
    "\n",
    "# Build FAISS over PDF chunks\n",
    "print(\"Embedding PDF chunks ...\")\n",
    "pdf_embeddings = embedder.encode(pdf_chunks, convert_to_numpy=True, show_progress_bar=True)\n",
    "dimension = pdf_embeddings.shape[1]\n",
    "index_pdf = faiss.IndexFlatL2(dimension)\n",
    "index_pdf.add(pdf_embeddings.astype(np.float32))\n",
    "\n",
    "print(f\"PDF index built with {len(pdf_chunks)} chunks. Embedding dim={dimension}\")\n",
    "\n",
    "# =========================\n",
    "# SerpAPI Web Search (no extra SDK)\n",
    "# =========================\n",
    "def web_search_serpapi(query: str, k: int = 8, hl: str = \"en\", gl: str = \"es\", last_year_only: bool = True) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Uses SerpAPI (Google) to fetch organic results.\n",
    "    Returns list of dicts: {title, url, content}\n",
    "    \"\"\"\n",
    "    if not SERPAPI_API_KEY:\n",
    "        return []\n",
    "\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query,\n",
    "        \"api_key\": SERPAPI_API_KEY,\n",
    "        \"num\": k,            # up to 10 typical\n",
    "        \"hl\": hl,            # language UI\n",
    "        \"gl\": gl,            # country bias\n",
    "        \"safe\": \"active\",\n",
    "        \"filter\": \"1\",       # remove similar\n",
    "    }\n",
    "    # Limit to recent results (last year) if needed\n",
    "    # tbs options: qdr:d (day), w (week), m (month), y (year)\n",
    "    if last_year_only:\n",
    "        params[\"tbs\"] = \"qdr:y\"\n",
    "\n",
    "    try:\n",
    "        r = requests.get(\"https://serpapi.com/search.json\", params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        org = data.get(\"organic_results\", []) or []\n",
    "        cleaned = []\n",
    "        for item in org:\n",
    "            title = item.get(\"title\", \"\")\n",
    "            link = item.get(\"link\", \"\") or item.get(\"url\", \"\")\n",
    "            snippet = item.get(\"snippet\", \"\") or item.get(\"content\", \"\")\n",
    "            if not link:\n",
    "                continue\n",
    "            cleaned.append({\n",
    "                \"title\": title,\n",
    "                \"url\": link,\n",
    "                \"content\": clean_text(snippet)[:2000]\n",
    "            })\n",
    "        return cleaned\n",
    "    except Exception as e:\n",
    "        print(f\"[web] SerpAPI error: {e}\")\n",
    "        return []\n",
    "\n",
    "def embed_texts(texts: List[str]) -> np.ndarray:\n",
    "    return embedder.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "# =========================\n",
    "# Hybrid retrieval (PDF + Web)\n",
    "# =========================\n",
    "def retrieve_hybrid(query: str, top_k_pdf: int = 5, top_k_web: int = 4) -> Tuple[List[Dict], List[Dict]]:\n",
    "    # PDF retrieval via FAISS\n",
    "    q_emb = embed_texts([query]).astype(np.float32)\n",
    "    distances, indices = index_pdf.search(q_emb, top_k_pdf)\n",
    "    pdf_hits = []\n",
    "    for rank, idx in enumerate(indices[0]):\n",
    "        score = -float(distances[0][rank])  # higher is better\n",
    "        pdf_hits.append({\n",
    "            \"text\": pdf_chunks[idx],\n",
    "            \"score\": score,\n",
    "            \"source\": pdf_chunk_meta[idx][\"source\"],\n",
    "            \"chunk_id\": pdf_chunk_meta[idx][\"chunk_id\"]\n",
    "        })\n",
    "\n",
    "    # Web retrieval via SerpAPI + re-rank with embeddings (cosine)\n",
    "    web_results = web_search_serpapi(query, k=8) if top_k_web > 0 else []\n",
    "    web_hits = []\n",
    "    if web_results:\n",
    "        web_texts = [w[\"content\"] for w in web_results if w.get(\"content\")]\n",
    "        if web_texts:\n",
    "            w_embs = embed_texts(web_texts).astype(np.float32)\n",
    "            qn = q_emb / (np.linalg.norm(q_emb, axis=1, keepdims=True) + 1e-12)\n",
    "            wn = w_embs / (np.linalg.norm(w_embs, axis=1, keepdims=True) + 1e-12)\n",
    "            sims = (wn @ qn[0])\n",
    "            top_idx = np.argsort(-sims)[:top_k_web]\n",
    "            for i in top_idx:\n",
    "                w = web_results[i]\n",
    "                web_hits.append({\n",
    "                    \"text\": w[\"content\"],\n",
    "                    \"score\": float(sims[i]),\n",
    "                    \"url\": w[\"url\"],\n",
    "                    \"title\": w.get(\"title\", \"\")\n",
    "                })\n",
    "\n",
    "    return pdf_hits, web_hits\n",
    "\n",
    "def make_context_blocks(pdf_hits: List[Dict], web_hits: List[Dict], max_chars: int = 2400) -> Tuple[str, List[str]]:\n",
    "    combined = []\n",
    "    for i in range(max(len(pdf_hits), len(web_hits))):\n",
    "        if i < len(pdf_hits): combined.append((\"pdf\", pdf_hits[i]))\n",
    "        if i < len(web_hits): combined.append((\"web\", web_hits[i]))\n",
    "\n",
    "    context_parts, citations, used = [], [], 0\n",
    "    for typ, item in combined:\n",
    "        snippet = item[\"text\"].strip()\n",
    "        if not snippet:\n",
    "            continue\n",
    "        header = f\"[PDF:{item['source']}#chunk{item['chunk_id']}]\" if typ == \"pdf\" else f\"[WEB:{item.get('title','')}]\"\n",
    "        block = f\"{header}\\n{snippet}\\n\"\n",
    "        if used + len(block) > max_chars:\n",
    "            break\n",
    "        context_parts.append(block)\n",
    "        used += len(block)\n",
    "        if typ == \"web\" and item.get(\"url\"):\n",
    "            citations.append(item[\"url\"])\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(context_parts), citations\n",
    "\n",
    "# =========================\n",
    "# Generation\n",
    "# =========================\n",
    "SYSTEM_INSTRUCTIONS = (\n",
    "    \"You are a credit risk and regulation assistant. \"\n",
    "    \"Use the provided context (PDF and web snippets) when relevant, \"\n",
    "    \"and you may also use your own knowledge. \"\n",
    "    \"When you use web snippets, include a 'Sources:' section with URLs.\"\n",
    ")\n",
    "\n",
    "def query_hybrid(prompt: str) -> str:\n",
    "    pdf_hits, web_hits = retrieve_hybrid(prompt, top_k_pdf=5, top_k_web=4)\n",
    "    context, urls = make_context_blocks(pdf_hits, web_hits, max_chars=2400)\n",
    "\n",
    "    final_prompt = (\n",
    "        f\"{SYSTEM_INSTRUCTIONS}\\n\\n\"\n",
    "        f\"User question: {prompt}\\n\\n\"\n",
    "        f\"Context below. Prefer it for factual grounding.\\n\"\n",
    "        f\"{'-'*40}\\n{context}\\n{'-'*40}\\n\\n\"\n",
    "        \"If you used any web evidence, add a short 'Sources:' list of URLs at the end.\"\n",
    "    )\n",
    "\n",
    "    response = model.generate_content(final_prompt)\n",
    "    text = response.text or \"\"\n",
    "    if urls:\n",
    "        uniq_urls = list(dict.fromkeys(urls))\n",
    "        text += \"\\n\\nSources:\\n\" + \"\\n\".join(uniq_urls)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Optional: rouge scorer if available\n",
    "try:\n",
    "    _rouge_scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "except Exception:\n",
    "    _rouge_scorer = None\n",
    "\n",
    "# NOTE: This cell relies on existing names from the notebook:\n",
    "# - query_hybrid(prompt) -> str\n",
    "# - embedder -> SentenceTransformer instance\n",
    "# If you want to evaluate already-collected responses, set call_model=False\n",
    "# and provide 'response' in each dataset entry.\n",
    "\n",
    "def _extract_urls(text: str) -> List[str]:\n",
    "    return re.findall(r\"https?://\\S+\", text)\n",
    "\n",
    "def _has_sources_section(text: str) -> bool:\n",
    "    return bool(re.search(r\"\\bSources:\\b\", text, flags=re.IGNORECASE)) or bool(_extract_urls(text))\n",
    "\n",
    "def _cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    na = np.linalg.norm(a) + 1e-12\n",
    "    nb = np.linalg.norm(b) + 1e-12\n",
    "    return float((a @ b.T) / (na * nb))\n",
    "\n",
    "def evaluate_single(prompt: str,\n",
    "                    reference: Optional[str] = None,\n",
    "                    call_model: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Run the genAI model (unless call_model is False) and compute automatic metrics.\n",
    "    Returns a dict with response, timing, cosine similarity (embedding), rouge-L (if available),\n",
    "    source detection and simple length stats.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    response = query_hybrid(prompt) if call_model else \"\"\n",
    "    latency = time.time() - start\n",
    "\n",
    "    # embeddings-based similarity (requires a reference)\n",
    "    cos_sim = None\n",
    "    if reference:\n",
    "        resp_emb = embedder.encode([response], convert_to_numpy=True)\n",
    "        ref_emb = embedder.encode([reference], convert_to_numpy=True)\n",
    "        cos_sim = _cosine_similarity(resp_emb[0], ref_emb[0])\n",
    "\n",
    "    # rouge-l (optional)\n",
    "    rouge_l_f = None\n",
    "    if reference and _rouge_scorer is not None:\n",
    "        scr = _rouge_scorer.score(reference, response)\n",
    "        rouge_l_f = scr[\"rougeL\"].fmeasure\n",
    "\n",
    "    urls = _extract_urls(response)\n",
    "    has_sources = _has_sources_section(response)\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response,\n",
    "        \"reference\": reference,\n",
    "        \"latency_s\": latency,\n",
    "        \"len_response_chars\": len(response),\n",
    "        \"num_urls\": len(urls),\n",
    "        \"has_sources_section\": has_sources,\n",
    "        \"cosine_sim\": cos_sim,\n",
    "        \"rougeL_f\": rouge_l_f,\n",
    "        \"urls\": urls,\n",
    "    }\n",
    "\n",
    "def evaluate_dataset(dataset: List[Dict],\n",
    "                     call_model: bool = True,\n",
    "                     show_progress: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    dataset: list of {\"prompt\": str, \"reference\": Optional[str], \"response\": Optional[str]}\n",
    "    If call_model=True, 'response' is ignored and query_hybrid is invoked for each prompt.\n",
    "    If call_model=False, 'response' must be present in each entry.\n",
    "    Returns a pandas DataFrame with metrics per item and prints a short summary.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        if show_progress:\n",
    "            print(f\"Evaluating {i+1}/{len(dataset)}\", end=\"\\r\")\n",
    "        prompt = item.get(\"prompt\")\n",
    "        reference = item.get(\"reference\")\n",
    "        if not call_model and \"response\" in item:\n",
    "            # Use provided response\n",
    "            resp = item[\"response\"]\n",
    "            # We create a tiny wrapper to avoid calling model\n",
    "            def _dummy_query(_p): return resp\n",
    "            global query_hybrid  # temporarily swap\n",
    "            _orig = query_hybrid\n",
    "            query_hybrid = _dummy_query\n",
    "            try:\n",
    "                r = evaluate_single(prompt, reference, call_model=True)\n",
    "            finally:\n",
    "                query_hybrid = _orig\n",
    "        else:\n",
    "            r = evaluate_single(prompt, reference, call_model=call_model)\n",
    "        results.append(r)\n",
    "    df = pd.DataFrame(results)\n",
    "    # summary\n",
    "    avg_cos = df[\"cosine_sim\"].dropna().mean() if \"cosine_sim\" in df else None\n",
    "    avg_rouge = df[\"rougeL_f\"].dropna().mean() if \"rougeL_f\" in df else None\n",
    "    pct_with_sources = 100.0 * df[\"has_sources_section\"].mean() if not df.empty else 0.0\n",
    "    print(\"\\n--- Evaluation summary ---\")\n",
    "    print(f\"Items: {len(df)}\")\n",
    "    if avg_cos is not None:\n",
    "        print(f\"Avg embedding cosine similarity (resp vs ref): {avg_cos:.4f}\")\n",
    "    if avg_rouge is not None:\n",
    "        print(f\"Avg ROUGE-L F1: {avg_rouge:.4f}\")\n",
    "    print(f\"% responses including a 'Sources' section or URLs: {pct_with_sources:.1f}%\")\n",
    "    print(f\"Avg latency (s): {df['latency_s'].mean():.2f}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Where does Capitalflow operate and what does it do?\n",
      "Capitalflow is based in **Dublin, Ireland**.\n",
      "\n",
      "It operates as a **Diversified lending Non-Bank Financial Institution (NBFI)**.\n",
      "\n",
      "Sources:\n",
      "*   [https://www.crunchbase.com/organization/capitalflow](https://www.crunchbase.com/organization/capitalflow)\n",
      "\n",
      "Sources:\n",
      "https://tracxn.com/d/companies/capitalflow/__eYxFS6jERHrPNkjB4s9uenQZsLlB529jQzaWC2Eag7E\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Q: Summarize PD calculation approaches relevant to Capitalflow's portfolio. Include regulatory references if possible.\n",
      "Capitalflow employs internal-data-driven approaches for Probability of Default (PD) calculation, primarily within the framework of its IFRS 9 Expected Credit Loss (ECL) models.\n",
      "\n",
      "**Capitalflow's PD Calculation Approaches:**\n",
      "\n",
      "1.  **Internal Data Utilisation:** Capitalflow leverages its extensive internal data, specifically from Q3 2016 to Q4 2024, for model building and recalibration of PD.\n",
      "2.  **Portfolio Segmentation:** The models are built with clear segmentation by portfolio type, including Asset Finance (AF) and Commercial Real Estate (CRE). This allows for tailored PD estimations reflecting the unique characteristics and risk profiles of different asset classes.\n",
      "3.  **Derivation of Behavioural Variables:** The modelling process includes the derivation of key behavioural variables, such as delinquency flags and cure periods. This indicates a focus on capturing actual customer payment behaviour and recovery patterns, which are critical for predicting future defaults.\n",
      "4.  **Mapping of Contractual Terms and Restructuring Indicators:** Contractual terms and any restructuring indicators are mapped, suggesting that the models account for changes in loan conditions that could impact default probabilities.\n",
      "5.  **Alignment with IFRS 9 Modelling Requirements:** All data transformations and model builds are designed to align with IFRS 9 requirements, ensuring that PD estimations are suitable for calculating Expected Credit Losses (ECL).\n",
      "\n",
      "**Regulatory References and Context:**\n",
      "\n",
      "1.  **IFRS 9 (International Financial Reporting Standard 9):** Capitalflow's PD modelling is explicitly framed within its IFRS 9 ECL model development. Under IFRS 9, financial institutions are required to recognize expected credit losses, for which PD is a critical input. The ECL is typically calculated as the product of Probability of Default (PD), Loss Given Default (LGD), and Exposure At Default (EAD). The emphasis on data transformation and model alignment with IFRS 9 requirements highlights compliance with this accounting standard.\n",
      "2.  **Internal Ratings-Based (IRB) Approach (Basel Accords):** While not explicitly named in the provided snippets, Capitalflow's approach of developing internal models for PD based on its own historical data, segmented portfolios, and behavioural variables is highly consistent with the principles of the Internal Ratings-Based (IRB) approach under the Basel Accords (e.g., Basel II, Basel III). Under IRB, banks that meet stringent regulatory requirements are permitted to use their own internal estimates of risk parameters like PD, LGD, and EAD for calculating regulatory capital. The reference to \"general methodology is largely aligned with common practice\" further supports this alignment with industry-standard advanced risk modelling techniques.\n",
      "3.  **Model Governance and Validation:** The documents emphasize robust governance controls, including audit trails, approval checkpoints, and compliance with regulatory and internal data standards. Furthermore, an independent validation by a third party (appointed by bunq) was conducted on Capitalflow's ECL model, including PD. The validation report confirmed the general methodology's alignment with common practice and deemed the model conditionally valid. Such independent validation and ongoing governance (e.g., review, feedback, and challenge sessions involving Capitalflow management and KPMG for proposed changes) are fundamental regulatory requirements under both IFRS 9 and Basel frameworks, ensuring the integrity, accuracy, and reliability of internal risk models. These practices are overseen by prudential regulators (e.g., Central Banks) to ensure financial stability and sound risk management.\n"
     ]
    }
   ],
   "source": [
    "q1 = \"Where does Capitalflow operate and what does it do?\"\n",
    "print(\"Q:\", q1)\n",
    "print(query_hybrid(q1))\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "q2 = \"Summarize PD calculation approaches relevant to Capitalflow's portfolio. Include regulatory references if possible.\"\n",
    "print(\"Q:\", q2)\n",
    "print(query_hybrid(q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 1/1\n",
      "--- Evaluation summary ---\n",
      "Items: 1\n",
      "Avg embedding cosine similarity (resp vs ref): 0.5787\n",
      "Avg ROUGE-L F1: 0.1000\n",
      "% responses including a 'Sources' section or URLs: 100.0%\n",
      "Avg latency (s): 3.65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>latency_s</th>\n",
       "      <th>len_response_chars</th>\n",
       "      <th>num_urls</th>\n",
       "      <th>has_sources_section</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>rougeL_f</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where does Capitalflow operate and what does i...</td>\n",
       "      <td>Capitalflow operates from **Dublin, Ireland**....</td>\n",
       "      <td>CapitalFlow Group (CFG) is an Irish subsidiary...</td>\n",
       "      <td>3.645576</td>\n",
       "      <td>348</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[https://www.crunchbase.com/organization/capit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Where does Capitalflow operate and what does i...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Capitalflow operates from **Dublin, Ireland**....   \n",
       "\n",
       "                                           reference  latency_s  \\\n",
       "0  CapitalFlow Group (CFG) is an Irish subsidiary...   3.645576   \n",
       "\n",
       "   len_response_chars  num_urls  has_sources_section  cosine_sim  rougeL_f  \\\n",
       "0                 348         2                 True    0.578698       0.1   \n",
       "\n",
       "                                                urls  \n",
       "0  [https://www.crunchbase.com/organization/capit...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Provide references (gold answers) when available.\n",
    "dataset = [\n",
    "    {\"prompt\": q1, \"reference\": \"CapitalFlow Group (CFG) is an Irsish subsidiary of bunq; it operates in Ireland and Northern Ireland offering CRE, Asset Finance and Invoice Discounting.\"}\n",
    "    #{\"prompt\": q2, \"reference\": \"<short gold summary of PD calculation approaches>\"},\n",
    "]\n",
    "df_metrics = evaluate_dataset(dataset, call_model=True)\n",
    "display(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
